{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(NewLine, '\\n')\n",
      ", (Identifier, 'Integer')\n",
      ", (Space, ' ')\n",
      ", (Identifier, 'x')\n",
      ", (Semicolon, ';')\n",
      ", (NewLine, '\\n')\n",
      ", (Identifier, 'Set')\n",
      ", (Space, ' ')\n",
      ", (Identifier, 'x')\n",
      ", (Space, ' ')\n",
      ", (OP, '=')\n",
      ", (Space, ' ')\n",
      ", (Num, '1')\n",
      ", (Semicolon, ';')\n",
      ", (NewLine, '\\n')\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class Token: #Token Class\n",
    "    def __init__(self, type, value):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'({self.type}, {repr(self.value)})\\n'\n",
    "\n",
    "class JASONScanner:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.position = 0\n",
    "        self.tokens = []\n",
    "        self.token_regex = self.build_token_regex()\n",
    "\n",
    "    def build_token_regex(self):\n",
    "        token_specification = [\n",
    "            ('Num',   r'\\d+(\\.\\d*)?'),          #Integer or decimal number\n",
    "            ('Identifier',    r'[A-Za-z_]\\w*'), #Identifiers\n",
    "            ('OP', r'[+\\-*/=]'),                #Operators\n",
    "            ('OpenBrace',   r'\\{'),             #Open Brace\n",
    "            ('ClosedBrace',   r'\\}'),           #Closed Brace\n",
    "            ('OpenBracket',   r'\\('),           #Open Bracket\n",
    "            ('ClosedBracket',   r'\\)'),         #Closed Bracket\n",
    "            ('Semicolon',r';'),                 #Semicolon\n",
    "            ('Space',     r'[ \\t]+'),           #Space\n",
    "            ('NewLine',  r'\\n'),                #End Line\n",
    "            ('Other', r'.'),                    #Other\n",
    "        ]\n",
    "        regex_patterns = '|'.join(f'(?P<{name}>{pattern})' \n",
    "                                  for name, pattern in token_specification)\n",
    "        return re.compile(regex_patterns)\n",
    "\n",
    "    def tokenize(self):\n",
    "        for match in re.finditer(self.token_regex, self.text):\n",
    "            kind = match.lastgroup\n",
    "            value = match.group()\n",
    "            if kind == 'SKIP' or kind == 'NEWLINE': #Does not produce error for space or newline\n",
    "                continue\n",
    "            elif kind == 'MISMATCH': #If scanner finds unrecognized item it will produce and error\n",
    "                raise RuntimeError(f'Illegal character {value!r} at position {self.position}/n')\n",
    "            else:\n",
    "                token = Token(kind, value)\n",
    "                self.tokens.append(token)\n",
    "            self.position = match.end()\n",
    "        return self.tokens\n",
    "\n",
    "\n",
    "#Input stated in document\n",
    "code = \"\"\"\n",
    "Integer x;\n",
    "Set x = 1;\n",
    "\"\"\"\n",
    "#Putting code through the scanner\n",
    "Scan = JASONScanner(code)\n",
    "tokens = Scan.tokenize()\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex patterns for JSON tokens\n",
    "token_patterns = {\n",
    "    'WHITESPACE': r'[ \\t\\n]+',  # Ignore whitespace\n",
    "    'LBRACE': r'\\{',\n",
    "    'RBRACE': r'\\}',\n",
    "    'LBRACKET': r'\\[',\n",
    "    'RBRACKET': r'\\]',\n",
    "    'COMMA': r',',\n",
    "    'COLON': r':',\n",
    "    'STRING': r'\\\"([^\"\\\\]|\\\\.)*\\\"',\n",
    "    'NUMBER': r'-?\\d+(\\.\\d+)?([eE][+-]?\\d+)?',\n",
    "    'TRUE': r'true',\n",
    "    'FALSE': r'false',\n",
    "    'NULL': r'null'\n",
    "}\n",
    "\n",
    "# Combine into a single pattern with named groups\n",
    "token_regex = '|'.join(f'(?P<{name}>{pattern})' for name, pattern in token_patterns.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    for match in re.finditer(token_regex, text):\n",
    "        kind = match.lastgroup\n",
    "        value = match.group()\n",
    "        if kind == 'WHITESPACE':\n",
    "            continue\n",
    "        elif kind == 'STRING':\n",
    "            value = value[1:-1].replace('\\\\\"', '\"')  # Remove quotes and handle escaped quotes\n",
    "        elif kind == 'NUMBER':\n",
    "            value = float(value) if '.' in value or 'e' in value or 'E' in value else int(value)\n",
    "        elif kind == 'TRUE':\n",
    "            value = True\n",
    "        elif kind == 'FALSE':\n",
    "            value = False\n",
    "        elif kind == 'NULL':\n",
    "            value = None\n",
    "        yield kind, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(tokens):\n",
    "    kind, value = next(tokens)\n",
    "    if kind in ['STRING', 'NUMBER', 'TRUE', 'FALSE', 'NULL']:\n",
    "        return value\n",
    "    elif kind == 'LBRACE':\n",
    "        return parse_object(tokens)\n",
    "    elif kind == 'LBRACKET':\n",
    "        return parse_array(tokens)\n",
    "    raise SyntaxError('Unexpected value')\n",
    "\n",
    "\n",
    "def parse_pair(tokens):\n",
    "    kind, key = next(tokens)\n",
    "    if kind != 'STRING':\n",
    "        raise SyntaxError('Expected string key')\n",
    "    kind, sep = next(tokens)\n",
    "    if kind != 'COLON':\n",
    "        raise SyntaxError('Expected colon separator')\n",
    "    value = parse_value(tokens)\n",
    "    return key, value\n",
    "\n",
    "\n",
    "def parse_object(tokens):\n",
    "    obj = {}\n",
    "    kind, sep = next(tokens)\n",
    "    if kind == 'RBRACE':\n",
    "        return obj  # Empty object\n",
    "    while True:\n",
    "        key, value = parse_pair(tokens)\n",
    "        obj[key] = value\n",
    "        kind, sep = next(tokens)\n",
    "        if kind == 'RBRACE':\n",
    "            break\n",
    "        elif kind != 'COMMA':\n",
    "            raise SyntaxError('Expected comma or closing brace')\n",
    "    return obj\n",
    "\n",
    "def parse_array(tokens):\n",
    "    arr = []\n",
    "    kind, sep = next(tokens)\n",
    "    if kind == 'RBRACKET':\n",
    "        return arr  # Empty array\n",
    "    while True:\n",
    "        tokens.append((kind, sep))  # Push back the last read token\n",
    "        value = parse_value(tokens)\n",
    "        arr.append(value)\n",
    "        kind, sep = next(tokens)\n",
    "        if kind == 'RBRACKET':\n",
    "            break\n",
    "        elif kind != 'COMMA':\n",
    "            raise SyntaxError('Expected comma or closing bracket')\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = iter(tokens)  # Create an iterator over tokens\n",
    "    value = parse_value(tokens)\n",
    "    try:\n",
    "        next(tokens)  # Ensure there are no extra tokens\n",
    "        raise SyntaxError('Unexpected data after JSON object')\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
